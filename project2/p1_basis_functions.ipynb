{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-577708d85f1c949d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Fitting with Radial Basis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4b64bd970e6e4fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T00:24:50.327000-04:00",
     "start_time": "2020-08-27T04:24:48.198Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea2ea5bf3af9e390",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In a previous assignment, you used linear regression to fit a set of nonlinear basis functions to a set of points in 3D (surface regression). In Project 2, we will explore a special nonlinear basis called the **radial basis functions** and see how these functions can be used to better fit a surface to a set of ponts. If you have heard of Machine Learning, a popular form of AI, then you'll be happy to know that radial basis functions are very common in Supervised Machine Learning!\n",
    "\n",
    "*Note:* As you walk through the notebook, if there is a cell that contains code or a step that you don't quite understand, feel free to create a new block right below the cell and type $\\texttt{@show}$ $\\texttt{variable_name}$ to display the contents of the variable. This can help to expose some of the intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:24.319000-04:00",
     "start_time": "2020-08-27T06:28:24.285Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbae9fd3594c2c75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "using Plots, LaTeXStrings, LinearAlgebra, Random\n",
    "gr()\n",
    "default(\n",
    "    titlefont = (16, \"times\"), \n",
    "    legendfontsize = 12, \n",
    "    guidefont = (14), # Changes x and y axis label fonts\n",
    "    linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T14:42:09.177000-04:00",
     "start_time": "2020-08-08T18:42:07.489Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f29e3b8672440817",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To build up intuition for some of the properties of the radial basis function, let's first explore trying to fit a curve to \"noisy\" measurements corresponding to a real-valued function. We will generate realistic measurements by selecting points on the x axis and adding \"noise\" (that is, random numbers) to the corresponding output value of the function. If this is abstract, you can think of the y values of the function as temperature values, the x values as the measurement time and the noise as the measurement error that is inherent to our specific sensor.\n",
    "\n",
    "Create a new cell block and type ``?randn`` to find out more about the noise being added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:25.558000-04:00",
     "start_time": "2020-08-27T06:28:25.477Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86788d654daf02ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will generate a plot for you. \n",
    "#\n",
    "# Create a known function with no noise\n",
    "\n",
    "x_actual = collect(1:0.01:2.5);\n",
    "y_actual = cos.(2π * x_actual) .* exp.(-x_actual);\n",
    "plot(x_actual, y_actual, title=L\"$f(x) = e^{-x}cos(2\\pi x)$\", legend=false)\n",
    "xlabel!(L\"x\")\n",
    "ylabel!(L\"f(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:26.138000-04:00",
     "start_time": "2020-08-27T06:28:26.084Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5908984bf36be6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will generate the following for you:\n",
    "#     - x_measured a vector of real numbers of points where the function is \"measured\"\n",
    "#     - y_measured a vector of real numbers of points corresponding to \"noisy\" measurements\n",
    "#     - A plot with our function + the points we sampled from it with noise\n",
    "\n",
    "# Randomly sample N points along the x axis\n",
    "N = 50\n",
    "\n",
    "# Allows us to get the same random numbers every time we run this cell\n",
    "Random.seed!(12345678)\n",
    "\n",
    "# We use unique because after flooring the numbers (rounding numbers to the nearest \n",
    "# integer less than or equal to the number), we may have repeated indices\n",
    "idx = Int.(unique(floor.(rand(N) * length(x_actual))) .+ 1) # random indices\n",
    "N   = length(idx);\n",
    "\n",
    "x_measured = x_actual[idx]; # Training input\n",
    "\n",
    "# Noise from a scaled normal distribution\n",
    "y_measured = y_actual[idx] + 0.02 * randn(N)\n",
    "\n",
    "plot(x_actual, y_actual, title=\"Noisy measurements from a known function\",\n",
    "    label=L\"$f(x) = e^{-x}cos(2\\pi x)$\", xlabel=L\"$x$\", ylabel=L\"$f(x)$\")\n",
    "scatter!(\n",
    "    x_measured, \n",
    "    y_measured, \n",
    "    c=:orange, # set the color\n",
    "    label=\"Noisy Measurements\", \n",
    "    legend=:best) # automatically use best location to place legend in graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T00:26:42.731000-04:00",
     "start_time": "2020-08-27T04:26:42.472Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0cbeac1ba7f0375c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now imagine that we were given the indicated noisy measurements and we would like to fit a function to them. Here, we know what the function is, but in practice, all we know are the measured values! How can we go about finding a function that explains the data?\n",
    "\n",
    "Let's start with trying to use a basis often used in the textbook, namely monomials (powers of x). Remember that the basis functions can themselves be nonlinear. It is only the way that we combine the functions together that needs to be linear (a linear combination). We refer to our suggested pipeline for fitting the measurements to the basis functions (in the booklet Least Squares via the QR factorization). The 'A' term in regression is sometimes called the phi ($\\Phi$) matrix or design matrix.\n",
    "\n",
    "[![QR-Axb-pipeline.png](https://i.postimg.cc/dtHdnyrV/QR-Axb-pipeline.png)](https://postimg.cc/kBSBgDT0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a1a08b4fc72cbe7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To efficiently solve for x in the pipeline, we can take advantage of R being an upper-triangular matrix and use back substitution. We bring the backwardsub function from HW4 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:27.650000-04:00",
     "start_time": "2020-08-27T06:28:27.636Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69123d7ab5b7dcf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will create a back substitution function that you can apply\n",
    "# to systems of linear equations with an upper triangular \"A\" matrix, that we denote by U\n",
    "\n",
    "\"\"\"\n",
    "backwardsub(U, b)\n",
    "\n",
    "It solves for x in an equation Ux = b, where U is upper triangular.\n",
    "\"\"\"\n",
    "function backwardsub(U, b)\n",
    "    \n",
    "    # Assert no entries in the diagonal of U\n",
    "    # are 0 (or very close to 0)\n",
    "    @assert minimum(abs.(diag(U))) > 1e-6\n",
    "    \n",
    "    n = length(b)\n",
    "    x = Vector{Float64}(undef, n)\n",
    "\n",
    "    x[n] = b[n] / U[n,n]\n",
    "    for i in n-1:-1:1\n",
    "        x[i]=(b[i] - (U[i,(i+1):n])' * x[(i+1):n]) ./ U[i,i]\n",
    "    end\n",
    "    \n",
    "    return x    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93d9c06227f1001a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our goal is to find a set of coefficients $a_1$, $a_2$, $a_3$, $a_4$ such that for every measured point $x_i$, our model produces a prediction or output as close to the actual $y_i$ value as possible. The error between our model prediction and our actual value is $e_i = y_i - \\hat{y}_i$.\n",
    "\n",
    "$$\\hat{y} = a_1 + a_2 x + a_3 x^2 + a_4 x^3 $$\n",
    "\n",
    "We refer to our coefficients collectively as $a_{star} = [a_1, a_2, a_3, a_4]$. As we will see in the next couple of cells, the use of monomials as basis functions will not be a great design choice here. However, we use it for the purpose of illustrating the value of radial basis functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8eaa2ae14fbb50cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1: Construct a Phi Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bfde0a9f3c7b3cd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With the model described above, we can form a set of linear equations where each equation is formed by evaluating the $x_i$ value of our measurement to obtain a predicted $\\hat{y}_i$ value.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y}_1 = a_1 + a_2x_1 + a_3x_1^2 + a_4x_1^3 \\\\\n",
    "\\hat{y}_2 = a_1 + a_2x_2 + a_3x_2^2 + a_4x_2^3 \\\\\n",
    "\\vdots\n",
    "\\end{equation*}\n",
    "\n",
    "With our linear equations written out, we can now write the set of linear equations succinctly as $\\hat{Y} = \\Phi a_{star}$. For Task 1, write in the code necessary to construct $\\Phi$ given our model. __Hint:__. Since our model has 4 coefficients, the size of $\\Phi$ will be N x 4 where N is the number of measurements we have taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:28.709000-04:00",
     "start_time": "2020-08-27T06:28:28.693Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-897afe635a702c77",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill in code to define the phi matrix.\n",
    "#\n",
    "# basis = [1, x, x^2, x^3]\n",
    "phi =\n",
    "\n",
    "# This is how you do QR Factorization of the matrix ``phi`` in Julia\n",
    "F = qr(phi)\n",
    "Q=Matrix(F.Q)\n",
    "R=Matrix(F.R)\n",
    "\n",
    "# Display Q and R to verify sizes and types\n",
    "@show size(phi);\n",
    "@show size(Q);\n",
    "@show size(R);\n",
    "@show typeof(Q);\n",
    "@show typeof(R);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2ed1436feb77d9ad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell\n",
    "### BEGIN HIDDEN TESTS\n",
    "p1_task1_phi = [ones(length(x_measured)) x_measured x_measured.^2 x_measured.^3];\n",
    "@assert isapprox(phi, p1_task1_phi)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T14:42:32.024000-04:00",
     "start_time": "2020-08-08T18:42:10.954Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fed5ca38407389a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In previous homeworks you used the Gram-Schmidt Process to construct the Q matrix. In this project we will use the $\\texttt{qr}$ function from the linear algebra package which produces the same Q and R matrices that can be obtained via Gram-Schmidt. Using the implementation in the qr package results in more numerically stable results (algorithms that naively divide frequently produce really small numbers which are hard for computers to represent accurately). To properly index into Q and R make sure to pass each component in the output to the $\\texttt{Matrix}$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-751fb2c42608e8ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Least Squares QR Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:30.126000-04:00",
     "start_time": "2020-08-27T06:28:30.045Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66ced968033a0079",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We continue our illustration of regression, where the least squared error fit\n",
    "# is determined via the QR Factorization. Run the cell, don't change anything. \n",
    "# Pay attention, though!\n",
    "#\n",
    "# Pipeline for Least Squares using QR factorization\n",
    "b_bar = Q' * y_measured\n",
    "a_star = backwardsub(R, b_bar)\n",
    "\n",
    "# Save the coefficients to be used for later\n",
    "a_monomial = copy(a_star)\n",
    "\n",
    "# Julia can represent characters in something known as unicode which\n",
    "# allows for typesetting using more than the keys on your keyboard.\n",
    "# To create the variable a₁ type a\\_1 and then hit tab\n",
    "# right after and julia will reformat your varaible name.\n",
    "@show a₁ = a_star[1];\n",
    "@show a₂ = a_star[2];\n",
    "@show a₃ = a_star[3];\n",
    "@show a₄ = a_star[4];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert 1 < 2, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01a5c52aa9b9bac2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, now that we have our weights for the basis, let's see how good our fit is by obtaining estimates of the function with our model at all points along the x axis used to plot the original function. A way to quantify how well our model fits is to calculate the total fitting error. We will calculate our error by comparing how well our model predicts the values we actually measured (remember, we wouldn't know the actual function in practice. We define the fitting error $E_{tot}$ below where $y_i$ is the true value obtained from our known function at $x_i$, and $\\hat{y}_i$ is the ouput of our model after evaluating it with $x_i$.\n",
    "\n",
    "$$E_{tot} = \\sum_{i=1}^{N}(e_i)^2 = e^\\intercal e = (\\hat{y}_i - y_i)^\\intercal(\\hat{y}_i - y_i) = ||\\hat{y}_i - y_i||^2_2$$\n",
    "\n",
    "\n",
    "The next cell provides us a small helper function to calculate this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d0b6516f3ca22da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me! I create a function that\n",
    "# helps to calculate the fitting error of our\n",
    "# monomial model\n",
    "\n",
    "\"\"\"\n",
    "error_monomial_fit(a, X)\n",
    "\n",
    "Calculates and returns the error E_tot defined as:\n",
    "\n",
    "            E_tot = Σ(yhat_i - y_i)^2\n",
    "\n",
    "between the monomial model and the actual function\n",
    "\"\"\"\n",
    "function error_monomial_fit(a, X)\n",
    "    \n",
    "    @assert size(a,1) == 4\n",
    "    \n",
    "    # Calculate the value of the model: y_hat = a₁ + a₂x + a₃x^2 + a₄x^3\n",
    "    y_hat = a[1]*ones(length(X)) + a[2]*X + a[3]*X.^2 + a[4]*X.^3\n",
    "\n",
    "    # Return the error E_tot\n",
    "    return (y_measured - y_hat)' * (y_measured - y_hat)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:30.886000-04:00",
     "start_time": "2020-08-27T06:28:30.853Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e33b391378fbfc72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me! We illustrate here how to generate \n",
    "# a plot of the estimated function and report the fitting error.\n",
    "# We use the same x points we used for drawing our original \n",
    "# function to draw our regressed function\n",
    "\n",
    "y_hat = a₁*ones(length(x_actual)) + a₂*x_actual + a₃*x_actual.^2 + a₄*x_actual.^3\n",
    "\n",
    "# Calculate and display the fitting error\n",
    "etot = error_monomial_fit(a_star, x_measured)\n",
    "println(\"Monomial Fitting Error: \", etot)\n",
    "\n",
    "plot(x_actual, y_hat, label=\"monomial model\", xlabel=L\"$x$\")\n",
    "plot!(x_actual, y_actual, label=\"actual function\")\n",
    "scatter!(x_measured, y_measured, c=:orange, label=\"Noisy Measurements\", \n",
    "    legend=:best, size=(800,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eabc1781eb6bf498",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "While the general shape seems to be identified, the crests in the plot do not match well and we can see that, if we were to extend the x axis in either direction, the two curves would diverge significantly. Let's plot the basis functions individually and get a feel for the individual functions we are adding up. As you move through the notebook, the goal will be to arrive at a model that will produce a lower fitting error than the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:31.659000-04:00",
     "start_time": "2020-08-27T06:28:31.604Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-067864e5897cc362",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run me, don't change me !\n",
    "#\n",
    "# I create two plots. The first plot shows a line for each of the 4 monomials \n",
    "# in our model. The second plot shows a picture of x^2 to use as a reference.\n",
    "\n",
    "l = @layout [a{0.7w} b{0.3w}]\n",
    "p1 = plot(x_actual, a₁*ones(length(x_actual)), label=L\"$\\phi_1(x) = a_1$\")\n",
    "plot!(p1, x_actual, a₂*x_actual, label=L\"$\\phi_2(x) = a_2 x$\")\n",
    "plot!(p1, x_actual, a₃*x_actual.^2, label=L\"$\\phi_3(x) = a_3 x^2$\")\n",
    "plot!(p1, x_actual, a₄*x_actual.^3, label=L\"$\\phi_4(x) = a_4 x^3$\",\n",
    "    legend=:outertopright)\n",
    "xlabel!(L\"$x$\")\n",
    "title!(\"Basis Functions\")\n",
    "\n",
    "x_sq = collect(-1:0.01:1)\n",
    "p2 = plot(x_sq, x_sq.^2, label=L\"x^2\")\n",
    "xlabel!(L\"$x$\")\n",
    "plot(p1, p2, layout=l, size=(800,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-816c5a6f507a3516",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are some things you might notice about each of the individual monimals you've plotted? If someone asked you to describe the shape of the $x^2$ you might say that it's bowl shaped. However, in the image above, we see only a portion of a _really_ big bowl. One of the issues of using the monomial basis functions is that if we take $x^2$ for example, regression tries to fit it to all the measurements. What if we could have it just fit ONLY the measurements near the bowl shape at $x$=1.5 in the orignal (actual) function. Said another way, what if we could _locally_ fit the basis functions to certain parts of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-524737d8282dff8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Radial Basis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6137af7755c6442",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$f(x; x_c, s) = exp(\\frac{-\\|x-x_c\\|^2}{2s^2})$$\n",
    "\n",
    "The equation above is the formula for a generic Radial Basis Function (RBF). $x$ and $x_c$  are vectors in $\\mathbb{R}^n$. Both $x_c$ and s are known before evaluating the function and are said to parameterize the function. Just as $y=2x$ and y=$-3x$ are both equations for lines but the value of the slope changes the steepness of the line, we will find that our radial basis function always has a bell-shaped curve that changes it's look based on the values of $x_c$ and $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:33.447000-04:00",
     "start_time": "2020-08-27T06:28:33.126Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For this cell, try out different values for each of the\n",
    "# three variables listed below with the suggested range for \n",
    "# each variable in the comments. The cell will display the \n",
    "# RBF function.\n",
    "\n",
    "## EDIT ##\n",
    "x1 = 0  # Try values between [-5, 5]\n",
    "xc = 0  # Try values between [-5, 5]\n",
    "s = 1   # Try values between [0.1, 2]\n",
    "## EDIT\n",
    "\n",
    "# The radial basis function\n",
    "rbf(x1, xc, s) = exp.(-norm(x1-xc)^2 / (2*s^2))\n",
    "\n",
    "x = collect(-5:0.1:5) .+ xc\n",
    "y = [rbf(val, xc, s) for val in x]\n",
    "    \n",
    "plot(x, y, xlabel=L\"$x$\", label=\"\\$f(x_1;x_c=0,s=$s)\\$\",\n",
    "    title=\"Radial Basis Function\", xlims=(-10,10))\n",
    "plot!([x1], [rbf(x1, xc, s)], marker=:orange, markersize=5, \n",
    "    label=L\"$x_1$\", legend=:outertopright, size=(800,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5339368700d0b765",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a few minutes to understand what how changing each input to the function affects the plot. As you play around with the inputs you should notice the following:\n",
    "\n",
    "* $x_1$: as $x_1$ get's further and further in either direction away from $x_c$, the value of the function becomes smaller. It is the largest when $x_1$ is exactly $x_c$. This makes sense because of we look at the numerator in the exponent of our RBF, $\\|x_1-x_c\\|^2$ just represents the norm (distance) between two vectors. However, because we are negating the power in the function ($\\exp(-...)$), large norms lead to small ouptut values.\n",
    "\n",
    "* $x_c$: changes where the peak of the bell curve lies. We can think of this as the function's center.\n",
    "\n",
    "* $s$: changes how narrow or wide our function is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21257a6746eea10b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Fitting By Hand with Radial Basis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d29098d29b6b38f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the last set of cells, we looked at how the inputs of the RBF change the shape of the function. In this task, we explore trying to fit our original real-valued function $f(x) = e^{-x}cos(2\\pi x)$ with two RBFs. We can write our model as follows (ignoring the constant term for now):\n",
    "\n",
    "$$\\hat{y} = a_1 f(x; x_{c_1}, s) + a_2 f(x; x_{c_2}, s)$$\n",
    "\n",
    "Note that in this formulation, the width parameter $s$ is shared between both RBFs. Typically when using RBF's there will be one width parameter shared among all of the basis functions. For the rest of this project, we will do so as well. In the next two cells, we provide two helper functions to plot our model and calculate the fitting error with our two RBF model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-820fdf8fcd6c5b6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will create a function\n",
    "# that will plot our 2 RBF model along with our\n",
    "# original function using the parameters provided\n",
    "\n",
    "\"\"\"\n",
    "plot_2rbf_model(a₁, xc1, a₂, xc2, s)\n",
    "\n",
    "Plots the 2 RBF model along with the original function.\n",
    "The model is defined as: \n",
    "\n",
    "       y_hat = a₁f(x; xc1, s) + a₂f(x; xc2, s)\n",
    "\"\"\"\n",
    "function plot_2rbf_model(a₁, xc1, a₂, xc2, s)\n",
    "    \n",
    "    # Calculate the value of the model: y_hat = a₁f(x; xc1, s) + a₂f(x; xc2, s)\n",
    "    # at each data point val in x_actual and arrange it as a vector\n",
    "    y_rbf = [a₁ * rbf(val, xc1, s) + a₂ * rbf(val, xc2, s) for val in x_actual]\n",
    "    \n",
    "    plot(x_actual, y_actual, title=\"Partial Data Fit\", line=:dash,\n",
    "        label=L\"$f(x) = e^{-x}cos(2\\pi x)$\", xlabel=L\"$x$\", ylabel=L\"$f(x)$\")\n",
    "    plot!(x_actual, y_rbf, label=\"\\$$a₁ f(x_1;x_c=$xc1,s=$s) + $a₂ f(x;x_c=$xc2,s=$s)\\$\")\n",
    "    scatter!(x_measured, y_measured, c=:orange, label=\"Noisy Measurements\", \n",
    "        legend=:best, size=(800,500)) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b00fed009466966",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will create a function\n",
    "# that will calculate the total error between our\n",
    "# model predicted values and the actual measurements\n",
    "\n",
    "\"\"\"\n",
    "error_2rbf_fit(a₁, xc1, a₂, xc2, s, x)\n",
    "\n",
    "Calculates and returns the error E_tot defined as:\n",
    "\n",
    "            E_tot = Σ(yhat_i - y_i)^2\n",
    "\"\"\"\n",
    "function error_2rbf_fit(a₁, xc1, a₂, xc2, s, x)\n",
    "    \n",
    "    # Calculate the value of the model: y_hat = a₁f(x; xc1, s) + a₂f(x; xc2, s)\n",
    "    # at each data point val in x and arrange it as a vector\n",
    "    y_hat = [a₁ * rbf(val, xc1, s) + a₂ * rbf(val, xc2, s) for val in x]\n",
    "    \n",
    "    return (y_measured - y_hat)' * (y_measured - y_hat)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50b3f4a8de1dad00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For this task, you will tune by hand 5 parameters to minimize the fitting error $E_{tot}$ of our model. The parameters $a_1$ and $a_2$ are the coefficients of our model, $xc1$ and $xc2$ are the centers of our RBFs and $s$ is the shared with parameter. Because we are only using two RBFs and are tuning the parameters by hand, the goal is to identify a parameter set the produces a total error that is less that 0.5.\n",
    "\n",
    "To start off, it is suggested to fit one RBF at a time. Set the coefficient $a_2$ to 0 if it is not 0 by default and adjust the parameters $a_1$, $xc1$, $s$ to approximately fit one of the two humps in the function. Once that's done, begin to modify $a_2$ and $xc2$. As you start fitting the second RBF, you may want to revisit some of your values for $s$, $a_1$, and $xc2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e893709275ce0eae",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell. In this cell you will tune the values in\n",
    "# the edit section to fit two RBFs to our original function\n",
    "# Each time you run this cell will plot the model defined\n",
    "# by the parameters as well as display the fitting error\n",
    "\n",
    "######     EDIT     ######\n",
    "a₁  = 1  # Try values in between [-1, 1] \n",
    "xc1 = 1.75  # Try values in between [1, 2.5]\n",
    "s   = 0.15  # Try values in between [0, 0.3]\n",
    "xc2 = 1.75  # Try values in between [1, 2.5]\n",
    "a₂  = 0    # Try values in between [-1, 1]\n",
    "######     EDIT     ######\n",
    "\n",
    "# Display error\n",
    "etot_2rbf = error_2rbf_fit(a₁, xc1, a₂, xc2, s, x_measured)\n",
    "etot_monomials = error_monomial_fit(a_monomial, x_measured)\n",
    "println(\"Monomial Fitting Error: \", etot_monomials)\n",
    "println(\"2 RBF Fitting Error   : \", etot_2rbf)\n",
    "\n",
    "# Plot model\n",
    "plot_2rbf_model(a₁, xc1, a₂, xc2, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ecd6ea3a21f78d5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell\n",
    "### BEGIN HIDDEN TESTS\n",
    "p2_task2_etot_2rbf = error_2rbf_fit(a₁, xc1, a₂, xc2, s, x_measured)\n",
    "@assert p2_task2_etot_2rbf < 0.5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7924b2234cc86e21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Congratulations! You have just fit using RBFs and we hope you can see that with just two bases that we are already getting a significantly better fit in the middle portion of the x-axis. At the moment, with just two basis, the total fitting error is still many times larger due to the deviation at the tails, but as we add more basis we can begin to get a closer fit at the ends of the function as well. A lot of the magic of the fit comes from the fact that values evaluated far away from the center of a RBF are very close to 0. This makes it very nice to use in our linear model. However, you still may have needed to have gone back and adjusted the parameters of the first RBF once you started adjusting the parameters of the second. Now that we have an understanding of the benefits of using RBFs for fitting, let's see if we can use our least squares pipeline to find a model and a set of coefficients that has a lower fitting error than our monomial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T01:23:16.652000-04:00",
     "start_time": "2020-08-27T05:23:16.648Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-245a3bdc1500af0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fitting using Least Squares and RBFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-614c5e1ef57beb49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To start using more RBFs in our model, let's first expand our model and also add back the constant term. M represents the number of RBFs we decide to use in our model.\n",
    "\n",
    "$$\\hat{y} = a_1 + a_2 f(x; x_{c_1}, s) + a_3 f(x; x_{c_2}, s) + ... + a_{M+1} f(x; x_{c_M}, s)$$\n",
    "\n",
    "Looking back up top to the least squares QR factorization excerpt from the book, to use the pipeline, the first step we need to do is construct the regressor matrix ($\\Phi$). When using the monomials, $\\Phi$ looked like so:\n",
    "\n",
    "$$\n",
    "\\begin{equation} \\label{eq:monomial_mat_form}\n",
    "    \\underbrace{\n",
    "    \\begin{bmatrix}\n",
    "    \\hat{y}_1 \\\\\n",
    "    \\hat{y}_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\hat{y}_N\n",
    "    \\end{bmatrix}}_{\\hat{Y}}\n",
    "    =\n",
    "    \\underbrace{\n",
    "    \\begin{bmatrix}\n",
    "    1 & x_1 & x_1^2 & x_1^3 \\\\\n",
    "    1 & x_2 & x_2^2 & x_2^3 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "    1 & x_N & x_N^2 & x_N^3\n",
    "    \\end{bmatrix}}_{\\Phi}\n",
    "    \\underbrace{\n",
    "    \\begin{bmatrix}\n",
    "    a_1 \\\\\n",
    "    a_2 \\\\\n",
    "    a_3 \\\\\n",
    "    a_4\n",
    "    \\end{bmatrix}}_{\\alpha}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "With our RBFs, a single row in our $\\Phi$ matrix can now be determined by following the below construction of a row where $x_i$ is the ith measurement out of N total measurements, $s$ is the shared RBF width parameter (also sometimes refered to by the name kernel width) and $x_{c_1}$ through $x_{c_m}$ are M different basis centers. The next few cells provide some useful helper functions that we will use in our pipeline.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & f(x_i;x_{c_1},s) & f(x_i;x_{c_2},s) & ... & f(x_i;x_{c_M},s) \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc86909fd8bea46c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will create a function\n",
    "# will be helpful in assembling our Φ matrix assuming\n",
    "# our model is a linear combination of RBFs\n",
    "\n",
    "\"\"\"\n",
    "function calc_phi_row(x, centers, s)\n",
    "\n",
    "Returns a single row in the Φ matrix\n",
    "\n",
    "Inputs:\n",
    "    xᵢ      - the measurment xᵢ\n",
    "    centers - a Mx1 vector holding the centers of the determined RBFs\n",
    "    s       - the shared kernel width (RBF width)\n",
    "\"\"\"\n",
    "function calc_phi_row(xᵢ, centers, s)\n",
    "   \n",
    "    phi_row_size = length(centers) + 1\n",
    "    phi_row = Array{Float64, 1}(undef, phi_row_size)\n",
    "    phi_row[1] = 1\n",
    "    \n",
    "    for i in 2:phi_row_size\n",
    "        phi_row[i] = rbf(xᵢ, centers[i-1], s)\n",
    "    end\n",
    "    \n",
    "    return phi_row\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:35.882000-04:00",
     "start_time": "2020-08-27T06:28:35.871Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53391b02b70e2da3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. I will create a function\n",
    "# that returns the regressor matrix Φ based on our\n",
    "# model using RBFs as basis functions\n",
    "\n",
    "\"\"\"\n",
    "function regressor_matrix()\n",
    "\n",
    "Returns the regressor matrix Φ\n",
    "\n",
    "Inputs:\n",
    "    X       - a Nx1 vector holding the X value of all the measurements\n",
    "    centers - a Mx1 vector holding the centers of the determined RBFs\n",
    "    s       - the shared kernel width (RBF width)\n",
    "\"\"\"\n",
    "function regressor_matrix(X, centers, s)\n",
    "    \n",
    "    N = length(X)\n",
    "    M = length(centers)\n",
    "    phi = Array{Float64, 2}(undef, N, M+1)\n",
    "    \n",
    "    for i in 1:N\n",
    "        phi[i, :] = calc_phi_row(X[i], centers, s)'\n",
    "    end\n",
    "    \n",
    "    return phi\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:36.691000-04:00",
     "start_time": "2020-08-27T06:28:36.683Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2773021b4f81b4b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me. \n",
    "\n",
    "\"\"\"\n",
    "function least_squares_qr(A::Array{Float64,2},  b::Array{Float64,1})\n",
    "\n",
    "Solves for x in Ax = b using the QR factorization. Returns x.\n",
    "\"\"\"\n",
    "function least_squares_qr(A::Array{Float64,2},  b::Array{Float64,1})\n",
    "    F = qr(A)\n",
    "    Q = Matrix(F.Q)\n",
    "    R = Matrix(F.R)\n",
    "    b_bar = Q' * b\n",
    "    return backwardsub(R, b_bar)    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T01:42:00.059000-04:00",
     "start_time": "2020-08-27T05:42:00.057Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6ec4926774a1dd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3: Identify the Fitting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a9966873202120a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have some helper functions, let's see how well we can fit our samples using radial basis functions and the least squares pipeline to calculate the optimal coefficients for our model. The goal of this task is to produce a fitting error that is less than the error we have with our monomial model. In this task, you will play around with the two parameters, $s$ and $M$, which you can set in the next cell. $s$ represents the width each RBF will use. $M$ represents the number of radial basis functions in our model. \n",
    "\n",
    "In the next cell, we use $M$ to select our basis centers and display them in a plot. The centers should be selected in the domain (x range) of the data, so we randomly select some of the measured x values to use as our centers. As we saw when we just used 2 RBFs, we need to place enough RBFs to sufficiently cover the domain of the data (so our model fits the tails of the function just as well as the middle of it). One way to achieve this is to randomly select values from the data to use as basis centers. Because $\\texttt{x_measured}$ is not sorted, when we select indices below, the centers will seem to appear at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7bb73b8560c121cf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell by changing the number of basis\n",
    "# functions (M) to use in our model and the width s.\n",
    "\n",
    "## Edit ##\n",
    "M = 9\n",
    "s = 0.3\n",
    "## Edit ##\n",
    "\n",
    "# If we have N measurements, select M of them evenly spaced by index from 1 to N\n",
    "# Note that because the measurements are not sorted as you change M, they\n",
    "# will appear to be selected at random from x_measured\n",
    "center_indices = Int.(floor.(collect(range(1, N, length=M))))\n",
    "\n",
    "# Creating a vector like this is known as using list comprehension\n",
    "# Read it as - for every element i in center_indices get the ith value in x_measured\n",
    "centers = [x_measured[i] for i in center_indices]\n",
    "println(\"Centers at x = \", centers)\n",
    "\n",
    "# Visually see selected RBF centers\n",
    "scatter(x_measured, zeros(N,1), markersize=5, c=:orange, label=\"Measurements\", title=\"Selected RBF centers\")\n",
    "scatter!(centers, zeros(M,1), markersize=5, c=:blue, label=\"RBF Centers\", legend=:best)\n",
    "ylims!((-0.1,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c29d00b8b0dcd9a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Note*: Some combinations of $M$ and $s$ result in a $U$ matrix in the backwardsub function whose columns are not linearly independent. In this case, you will be met with an assertion error that checks if any of the diagonal elements are close to 0: $\\texttt{minimum(abs.(diag(U))) > 1.0e-6}$. This happens when some basis centers are really close and the $s$ value is large. Consider using a smaller $s$ value or changing the value of $M$ to obtain a different set of centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6733f9d8ead7a66e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me! I implement the \n",
    "# least squares pipeline\n",
    "\n",
    "# Calculate the coefficients in the model\n",
    "phi = regressor_matrix(x_measured, centers, s)\n",
    "\n",
    "a_star = least_squares_qr(phi, y_measured)\n",
    "\n",
    "# Using the model, estimate the value at every x value we used to\n",
    "# to plot the original function. We can reuse our calc_phi_row\n",
    "# function to quickly evaluate the x value at each RBF and \n",
    "# evaluate the linear combination using vector multiplication\n",
    "for i in 1:length(x_actual)\n",
    "   y_hat[i] = a_star' * calc_phi_row(x_actual[i], centers, s)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41aaefa95d15c8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me! I implement a helper\n",
    "# function the computes the fitting error using\n",
    "# the multiple RBF model \n",
    "\n",
    "\"\"\"\n",
    "error_rbf_fit(a_star, centers, s, X)\n",
    "\n",
    "Calculates and returns the error E_tot defined as:\n",
    "\n",
    "            E_tot = Σ(yhat_i - y_i)^2\n",
    "\n",
    "between the rbf model and the actual function\n",
    "\n",
    "Inputs:\n",
    "    a_star  - a M+1 element vector with the coefficients for our model\n",
    "    centers - a Mx1 vector indicating where the center of each RBF along\n",
    "              the x axis is located\n",
    "    s       - the shared width parameter for all RBFs\n",
    "    X       - a Nx1 vector of data points that shall be predicted with\n",
    "              our model\n",
    "\"\"\"\n",
    "function error_rbf_fit(a_star, centers, s, X)\n",
    "    \n",
    "    y_hat = Array{Float64, 1}(undef, length(X))\n",
    "    for i in 1:length(X)\n",
    "        y_hat[i] = a_star' * calc_phi_row(X[i], centers, s)\n",
    "    end\n",
    "\n",
    "    # Return the error E_tot\n",
    "    return (y_measured - y_hat)' * (y_measured - y_hat)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T02:28:39.419000-04:00",
     "start_time": "2020-08-27T06:28:39.380Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b3626500c712b42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me, don't change me! I compare the monomial\n",
    "# fitting error with the error of our new RBF model\n",
    "# and additionally display the fit\n",
    "\n",
    "# Calculate and display the fitting error\n",
    "etot_monomial = error_monomial_fit(a_monomial, x_measured)\n",
    "etot_rbf = error_rbf_fit(a_star, centers, s, x_measured)\n",
    "println(\"Monomial Fitting Error: \", etot_monomial)\n",
    "println(\"RBF Fitting Error     : \", etot_rbf)\n",
    "\n",
    "# Plot the results\n",
    "plot(x_actual, y_hat, label=\"RBF Model\")\n",
    "plot!(x_actual, y_actual, label=L\"$f(x) = e^{-x}cos(2\\pi x)$\", xlabel=L\"$x$\",)\n",
    "scatter!(x_measured, y_measured, c=:orange, label=\"Noisy Measurements\", legend=:best)\n",
    "title!(\"Function fitting using radial basis functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-102081e799f8e1ae",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell\n",
    "### BEGIN HIDDEN TESTS\n",
    "task3_etot_rbf = error_rbf_fit(a_star, centers, s, x_measured)\n",
    "@assert task3_etot_rbf < etot_monomial\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0614d568ed7b572",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05d3c76d75beb7a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have seen in this notebook that we can use radial basis functions to create a smooth fit. In project 2, instead of taking data and fitting a line (1D), we attempt to take 2D data and fit a surface to it. Spend some time thinking about what the parameters of the radial basis function, specifically what $x_c$  and $s$ represent, when the problem is extended into 2D."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
